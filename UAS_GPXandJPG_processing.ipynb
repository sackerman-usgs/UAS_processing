{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAS_processing\n",
    "Creators: Seth Ackerman (@sackerman-usgs), Emily Sturdivant (@esturdivant-usgs)\n",
    "\n",
    "Jupyter notebook to process image and GPX files.\n",
    "\n",
    "## Pre-reqs:\n",
    "\n",
    "1. Convert the tlog file to gpx. We use Mission Planner with the computer time zone set to UTC.\n",
    "\n",
    "## Detailed workflow:\n",
    "\n",
    "1. **Read the GPX file.** View a dataframe from the GPX file.\n",
    "2. **Parse the time** field in the GPX dataframe. Add fields datetime_utc and epoch_utc.\n",
    "3. Export the dataframe as a table in CSV format and map the flight path from the GPX navigation data.\n",
    "4. Plot the flight path on an aerial photo basemap.\n",
    "5. Initialize a dataframe for the images. Include the original filename and the time in UTC, Epoch, and ISO formats.\n",
    "6. Export a CSV of the dataframe. Plot the image times and the GPX elevations by time to check that they match.\n",
    "8. **Geotag the photos** from the GPX file using the Geosync tool in ExifTool.\n",
    "7. **Rename the photos** using the survey number, the flight and camera ID, the time in ISO format, and the original filename.\n",
    "9. **Update EXIF tags** to standard values.\n",
    "\n",
    "## Requirements\n",
    "Python 3 with modules (in addition to defaults):\n",
    "\n",
    "- lxml\n",
    "- Pillow, a fork of PIL for Image processing\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- ipyleaflet\n",
    "\n",
    "We recommend creating the uas-processing conda environment from the YML file in this repo.\n",
    "\n",
    "```\n",
    "conda env create -f uas-processing.yml\n",
    "```\n",
    "\n",
    "### To use ipyleaflet\n",
    "\n",
    "Try this:\n",
    "```\n",
    "conda install -c conda-forge ipyleaflet\n",
    "```\n",
    "If that doesn't work:\n",
    "\n",
    "```\n",
    "pip install ipyleaflet\n",
    "jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "```\n",
    "If that fails on the second line: (If it fails on the first line you're screwed.)\n",
    "```\n",
    "conda update numpy\n",
    "jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "```\n",
    "If that doesn't work, find a solution and fix it for us!\n",
    "\n",
    "#### If using jupyter lab\n",
    "\n",
    "```\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```\n",
    "and follow directions to install dependencies (nodejs, npm)\n",
    "\n",
    "## Inputs/outputs\n",
    "\n",
    "Variables:\n",
    "\n",
    "- homedir: working directory that contains image folder and tlog folder (with gpx file) and where outputs will be saved.\n",
    "- flight: flight ID that matches the image folder name and the gpx file, usually in format fX\n",
    "- logfile: gpx file path\n",
    "- imagefolder: image folder path\n",
    "\n",
    "Output products:\n",
    "\n",
    "- CSV of pertinent telemetry data converted from GPX\n",
    "- PNG of flight path created from GPX\n",
    "- new folder of images with standardized filenames and image headers populated with contextual information\n",
    "\n",
    "Look for options to customize the geotag portion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and define the namespace for the GPX schema\n",
    "\n",
    "If you get an error here, you will have to add packages to your Python distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string, copy, sys, subprocess\n",
    "import shutil\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lxml import etree\n",
    "from PIL import Image, ExifTags\n",
    "import ipyleaflet as ipyl\n",
    "\n",
    "# set pandas output to limit to N records\n",
    "pd.set_option('max_rows', 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local filepaths:\n",
    "homedir = r'C:\\Users\\esturdivant\\Desktop\\test_photos' # '/Data/2018_PlumIsland/2018_015_FA_PlumIs_Feb/test_script/ricoh'\n",
    "logfile = r'C:\\Users\\esturdivant\\Desktop\\test_photos\\nav\\log_udp_2018_09_12_11_20_22_104_flight1.gpx'\n",
    "imagefolder = r'C:\\Users\\esturdivant\\Desktop\\test_photos\\f1'\n",
    "\n",
    "# Mission info - would be nice for logfile and image folder names to correspond to naming convention, as below\n",
    "fan = '2018-015-FA' # input('Field activity number (e.g. \"2017-010-FA\"): ')\n",
    "flight_id = 'f01' \n",
    "cam_id = 'r01' \n",
    "location = 'Pelican Island'\n",
    "state = 'Alabama'\n",
    "\n",
    "# Geotag value: \n",
    "# - If images and GPX file were created in UTC, use -0:0:0. \n",
    "geosync = '-0:0:0'\n",
    "\n",
    "# Automated file/folder names\n",
    "navcsvoutfile = os.path.splitext(logfile)[0]+'_gpx.csv'\n",
    "imgoutdir = imagefolder+'_new'\n",
    "\n",
    "# WHSC EXIF population\n",
    "credit = \"U.S. Geological Survey\"\n",
    "comment = \"\"\"Low-altitude aerial photograph of {0}, {1} from \n",
    "survey {2} (https://cmgds.marine.usgs.gov/fan_info.php?fa={2}).\"\"\".format(location, state, fan)\n",
    "keywords = \"{}, {}, {}, UAS, nadir, USGS\".format(location, state, fan)\n",
    "artist = \"WHCMSC AIM Group\"\n",
    "contact = \"WHSC_data_contact@usgs.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE: prompt for user input\n",
    "\n",
    "# homedir = input(\"Which directory contains your raw images and telemetry data (e.g. {})? \".format(homedir))\n",
    "# flightdirname = input(\"Which flight? Must match folder name in tlogs folder (e.g. f6). \")\n",
    "# logfile = os.path.join(homedir,'tlogs', flightdirname+'.gpx')\n",
    "# imagefolder = os.path.join(homedir,'images', flightdirname)\n",
    "# fan = input('Field activity number (e.g. \"2017-010-FA\"): ')\n",
    "# flight_id = input('Flight number (e.g. \"f04\"): ') \n",
    "# cam_id = input('Camera code (e.g. \"r01\"): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the user input data looks right before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(homedir):\n",
    "    print(\"We don't see the specified directory (homedir variable): {}\".format(homedir))\n",
    "    sys.exit()\n",
    "elif not os.path.isfile(logfile):\n",
    "    print(\"We don't see the specified file (logfile variable): {}\".format(logfile))\n",
    "    sys.exit()\n",
    "elif not os.path.isfile(navcsvoutfile):\n",
    "    print(\"We don't see the specified file (navcsvoutfile variable): {}\".format(navcsvoutfile))\n",
    "    sys.exit()\n",
    "elif not os.path.isdir(imagefolder):\n",
    "    print(\"We don't see the specified directory (imagefolder variable): {}\".format(imagefolder))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Your input files and folders are all present. Well done! Carry on.\")\n",
    "\n",
    "input_check = \"\\nFA = {}    \\nflight = {}    \\nsensor = {}\".format(fan, flight_id, cam_id)\n",
    "print (\"\\nInput data: \"+ input_check)\n",
    "\n",
    "print('Does the input data above look right?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse GPX file and extract components into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_tag_to_pdseries(tree, namespace, tag):\n",
    "    \"\"\"\n",
    "    # Extract tag value from GPX file as pandas series\n",
    "    First, get the element list.\n",
    "    \"\"\"\n",
    "    elist = tree.xpath('./def:trk//def:trkpt//def:'+tag, namespaces=namespace)\n",
    "    ser = pd.Series([e.text for e in elist], name=tag)\n",
    "    return(ser)\n",
    "\n",
    "# Parse GPX\n",
    "tree = etree.parse(logfile)\n",
    "\n",
    "# Extract latitude and longitude to initialize GPX dataframe\n",
    "namespace = {'def': 'http://www.topografix.com/GPX/1/1'}\n",
    "elist = tree.xpath('./def:trk//def:trkpt',namespaces=namespace)\n",
    "gpxdf = pd.DataFrame([e.values() for e in elist], columns=['lat', 'lon']).apply(pd.to_numeric)\n",
    "\n",
    "# Extract each tag (including time) and add to dataframe\n",
    "taglist = ['time', 'ele', 'ele2', 'course', 'roll', 'pitch', 'mode']\n",
    "for tag in taglist:\n",
    "    gpxdf = gpxdf.join(pd.to_numeric(gpx_tag_to_pdseries(tree, namespace, tag), errors='ignore'))\n",
    "\n",
    "# Check number of records and number of unique times \n",
    "print (\"Number of records in GPX file: \", len(gpxdf.index))\n",
    "print (\"Number of unique time stamps in GPX file: {}\\n\".format(len(gpxdf.time.unique())))\n",
    "\n",
    "gpxdf.describe()\n",
    "gpxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add datetime field to gpxdf dataframe\n",
    "\n",
    "Convert the time field to: \n",
    "\n",
    "- datetime_utc: datetime in UTC\n",
    "- epoch_utc: Unix epoch time, which counts seconds from January 1, 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in 'time' field to datetime UTC and convert datetime UTC to Epoch UTC\n",
    "tfmt_gpx = '%Y-%m-%dT%H:%M:%S' #e.g. 2017-05-04T14:14:12-04:00\n",
    "gpxdf['datetime_utc'] = pd.to_datetime(gpxdf['time'], format = tfmt_gpx)\n",
    "gpxdf['epoch_utc'] = gpxdf['datetime_utc'].astype(np.int64) // 10**9\n",
    "\n",
    "## this applies the local time zone offset to create a UTC epochtime value\n",
    "## March 2018 - commented out the tzoffset part for Plum Island survey - collected in UTC\n",
    "# gpxdf['epoch_utc'] = gpxdf['epoch_utc'].astype(str).astype(int) \n",
    "\n",
    "gpxdf_uniquetimes = gpxdf.drop_duplicates(subset='time')\n",
    "print(\"Number of records in unique times GPX file: \", len(gpxdf_uniquetimes.index))\n",
    "\n",
    "gpxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export (csv) and plot (png) the GPX data\n",
    "\n",
    "We're not sure how the interpolation works. Does simply '-' tell it to plot as a line, which includes interpolation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export CSV\n",
    "gpxdf.to_csv(navcsvoutfile, index=False)\n",
    "print (\"Exported output CSV file to:\", navcsvoutfile,\"\\n\")\n",
    "\n",
    "# Plot the flight path\n",
    "fig=plt.figure(figsize=(6, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax1 = plt.subplot(1,1,1)\n",
    "ax1.plot(gpxdf.lon, gpxdf.lat,'.', c='green', label=\"original gpx points\")\n",
    "ax1.plot(gpxdf.lon, gpxdf.lat,'-', c='yellow', label=\"original gpx line\")\n",
    "ax1.legend()\n",
    "ax1.set_title('GPX track for flight {}'.format(flight_id), fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Save the plot as a PNG file - might need to exit the save path\n",
    "fig.savefig(os.path.join(homedir, \"{}_gpxtrack.png\".format(os.path.splitext(logfile)[0])))\n",
    "fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot GPX on basemap – uses ipyleaflet and opens inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_linestring(df, lat='lat', lon='lon', z='ele'):\n",
    "    \"\"\"\n",
    "    Turn a dataframe containing point data into a linestring in geojson format\n",
    "    modified from: https://github.com/gboeing/urban-data-science/blob/3faf7e028d48cb03ddb999c5a910213c5384e7dc/17-Leaflet-Web-Mapping/leaflet-simple-demo/pandas-to-geojson.ipynb\n",
    "    \n",
    "    df : the dataframe to convert to geojson\n",
    "    lat : the name of the column in the dataframe that contains latitude data\n",
    "    lon : the name of the column in the dataframe that contains longitude data\n",
    "    \"\"\"\n",
    "    # create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    \n",
    "    # create a feature template to fill in\n",
    "    feature = {'type':'Feature',\n",
    "               'properties':{},\n",
    "               'geometry':{'type':'LineString',\n",
    "                           'coordinates':[]}}\n",
    "    \n",
    "    # loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        # fill in the coordinates\n",
    "        feature['geometry']['coordinates'].append([row[lon],row[lat],row[z]])\n",
    "\n",
    "    # add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "    geojson['features'].append(feature)\n",
    "    \n",
    "    return(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: figure out a way to cache the map layer or load a geotiff so we can do this offline\n",
    "m = ipyl.Map(\n",
    "    center=[np.mean([max(gpxdf.lat), min(gpxdf.lat)]), np.mean([max(gpxdf.lon), min(gpxdf.lon)])], \n",
    "    zoom=16, \n",
    "    layout=dict(width='600px', height='400px'), \n",
    "    basemap=ipyl.basemaps.Esri.WorldImagery)\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    print(action)\n",
    "    print(geo_json)\n",
    "    \n",
    "dc = ipyl.DrawControl()\n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "\n",
    "# Plotting the points (even only the unique times) is unwieldy. Plotting all points crashed my kernel. Plotting the unique ones worked, but there's  no apparent way to customize the point display. \n",
    "flight_path = df_to_linestring(gpxdf)\n",
    "m.add_layer(ipyl.GeoJSON(data=flight_path))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the photos\n",
    "\n",
    "Quirks from ExifTool that required work-arounds: \n",
    "\n",
    "- ExifTool assumes that both the GPS and the image times are local unless another timezone is specified (unless taken from GPSTimeStamp which is UTC).\n",
    "\n",
    "We normally set our camera to UTC and save the GPX files in UTC (by setting the computer time to UTC before running the Mission Planner conversion). Thus, running -geotag on a computer in local time without the '-geotime<${{DateTimeOriginal}}+00:00' part causes the camera times to be incorreclty adjusted to UTC. Our work-around uses the command to geotag images for which the camera clock was set to UTC (+00:00), using the time from DateTimeOriginal. It would also work to change the geosync value to account for this. \n",
    "\n",
    "This process uses PIL through Pillow, a fork that updates to PIL to Python 3, but an alternative would be to use a one line call to exiftool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ExifTool command to geotag images with a GPX file\n",
    "# Geotag images for which the camera clock was set to UTC (+00:00), using the time from DateTimeOriginal: (from ExifTool docs)\n",
    "cmd = \"\"\"exiftool -v2 -geotag {} -geosync={} '-geotime<${{DateTimeOriginal}}+00:00' {}\"\"\".format(logfile, \n",
    "                                                                                                 geosync, imagefolder) \n",
    "subprocess.check_call(cmd, shell=True) \n",
    "\n",
    "#TODO: enable customization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename images using exiftool\n",
    "# surveyid = fan.replace(\"-\",\"\")\n",
    "# cmd = \"\"\"exiftool -d {}_{}{}_%Y%m%dT%H%M%SZ_%%f.%%e \"-filename<GPSTimeStamp\" {}\"\"\".format(surveyid, cam_id, flight_id, imagefolder)\n",
    "# subprocess.check_call(cmd, shell=True) \n",
    "# cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all JPEGS in imagefolder\n",
    "flist=[os.path.join(imagefolder,f) for f in os.listdir(imagefolder) if f.lower().endswith('.jpg')]\n",
    "print(\"Found {} images in {}.\".format(len(flist),imagefolder))\n",
    "\n",
    "# Set datetime formats\n",
    "iso_fmt=\"%Y%m%dT%H%M%SZ\"\n",
    "tfmt_exif = '%Y:%m:%d %H:%M:%S' #e.g. 2017:05:04 14:14:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_datetime(f):\n",
    "    timestr = list(str(int(x/y)) for x, y in Image.open(f)._getexif()[34853][7])\n",
    "    datestr = Image.open(f)._getexif()[34853][29]\n",
    "    datetimestr = '{} {}'.format(datestr, ':'.join(timestr))\n",
    "    return(datetimestr)\n",
    "dt = [datetime.datetime.strptime(get_datetime(f), tfmt_exif) for f in flist]\n",
    "\n",
    "# Make dataframe from photo exif values\n",
    "imgdf = pd.DataFrame({'orig_name': [os.path.basename(f) for f in flist],\n",
    "                      'time_utc': dt,\n",
    "                      'time_epoch': pd.to_datetime(dt, format = tfmt_exif).astype(np.int64) // 10**9, \n",
    "                      'time_iso': [t.strftime(iso_fmt) for t in dt],\n",
    "                      'new_name': np.nan,\n",
    "                      'lon': np.nan,\n",
    "                      'lat': np.nan,\n",
    "                      'ele': np.nan,\n",
    "                      'interpolated': 0},\n",
    "                        columns=['new_name', 'lat', 'lon', 'ele', 'time_utc', 'orig_name', \n",
    "                                 'time_epoch', 'time_iso', 'interpolated'])\n",
    "\n",
    "imgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV for original photo EXIF times\n",
    "imgcsvoutfile = imagefolder+'_imgtmp.csv'\n",
    "imgdf.to_csv(imgcsvoutfile, index=False)\n",
    "print (\"Exported photo CSV file as:\", imgcsvoutfile,\"\\n\")\n",
    "            \n",
    "# print first and last image name and times\n",
    "print(\"First file: {}, time: {}\".format(imgdf.orig_name.iloc[0],imgdf.time_utc.iloc[0]))\n",
    "print(\"Last file: {}, time: {}\".format(imgdf.orig_name.iloc[-1],imgdf.time_utc.iloc[-1]),\"\\n\")\n",
    "# print first and last times in .gpx file\n",
    "print(\"GPX data: {} from {} to {}\".format(logfile, gpxdf.datetime_utc.iloc[0],gpxdf.datetime_utc.iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Plot times of image vs GPX data\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(gpxdf.datetime_utc, gpxdf.ele,'.c', label='GPX')\n",
    "# ax.plot(imgdf.time_utc, np.tile(gpxdf.ele.max(), imgdf.shape[0]),'.r', label='photo')\n",
    "# ax.legend()\n",
    "# #fig.clear()\n",
    "\n",
    "#%% Plot times of image vs GPX data\n",
    "fig = plt.figure(figsize=(6, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.plot(gpxdf.datetime_utc, gpxdf.ele,'.c', label='GPX')\n",
    "ax.plot(imgdf.time_utc, np.tile(gpxdf.ele.max(), imgdf.shape[0]),'.r', label='photo')\n",
    "ax.legend()\n",
    "ax.set_title('Flight altitude over time with photo times', fontsize=16)\n",
    "plt.show()\n",
    "fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: don't run if the names have already been changed...\n",
    "rename_photos = True\n",
    "\n",
    "surveyid = fan.replace(\"-\",\"\")\n",
    "if not os.path.exists(imgoutdir):\n",
    "    shutil.copytree(imagefolder, imgoutdir)\n",
    "for idx, row in imgdf.iterrows():\n",
    "    img = row.orig_name\n",
    "    namestr = \"{}_{}{}_{}_{}\".format(surveyid, flight_id, cam_id, row.time_iso, img)\n",
    "    if rename_photos:\n",
    "        os.rename(os.path.join(imagefolder, img), os.path.join(imgoutdir, namestr))\n",
    "    imgdf.loc[idx, 'new_name'] = namestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotag photos & add standard USGS metadata to EXIF headers\n",
    "I needed to hard code the location of exiftools - this might be different depending on ExifTools install. If needed, you can always run it at the command line flight-by-flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the ExifTool command to geotag images with a GPX file\n",
    "# cmd = \"\"\"exiftool -geosync=-0:0:0 -geotag {} {}\"\"\".format(logfile, imgoutdir)\n",
    "# subprocess.check_call(cmd, shell=True)\n",
    "# # Alternative?: subprocess.check_call(\"/usr/local/bin/exiftool -geosync=-0:0:0 -geotag {} {}\"\"\".format(logfile, imgoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_WHSC_exiftags(imgdir, credit, comment, keywords, artist, contact):\n",
    "    # Tags that will be identical for all images in the folder\n",
    "    tagvalues = {}\n",
    "    tagvalues['imgdir'] = imgdir\n",
    "    tagvalues['credit'] = credit\n",
    "    tagvalues['artist'] = artist\n",
    "    tagvalues['contact'] = contact\n",
    "    tagvalues['comment'] = comment\n",
    "    tagvalues['keywords'] = keywords\n",
    "    tagvalues['copyright'] = \"Public Domain. Please credit {credit}\".format(**tagvalues)\n",
    "    # Write to EXIF\n",
    "    cmd = \"\"\"exiftool -Artist=\"{artist} \" -Credit=\"{credit} \" -Contact=\"{contact} \" -comment=\"{comment} \" -sep \", \" -keywords=\"{keywords} \" -Caption=\"{comment} \" -Copyright=\"{copyright} \" -CopyrightNotice=\"{copyright} \" -Caption-Abstract=\"{comment} \" -ImageDescription=\"{comment} \" {imgdir}\"\"\".format(**tagvalues)\n",
    "    subprocess.check_call(cmd, shell=True)\n",
    "    print(\"Updated Exif headers in directory: {}\".format(imgdir))\n",
    "    return(True)\n",
    "\n",
    "# Run ExifTool again to update other USGS specific meta tags\n",
    "write_WHSC_exiftags(imgoutdir, credit, comment, keywords, artist, contact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
