{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAS_processing\n",
    "Creators: Seth Ackerman (@sackerman-usgs), Emily Sturdivant (@esturdivant-usgs)\n",
    "\n",
    "Jupyter notebook to process image and GPX files.\n",
    "\n",
    "\n",
    "## Detailed workflow:\n",
    "\n",
    "1. Read the GPX file, which is a telemetry log file produced by the 3DR Solo in tlog format and converted to GPX in Mission Planner. View a dataframe from the GPX file.\n",
    "2. Parse the time field in the GPX dataframe. Add fields datetime_utc and epoch_utc.\n",
    "3. Export the dataframe as a table in CSV format and map the flight path from the GPX navigation data.\n",
    "4. Plot the flight path on an aerial photo basemap.\n",
    "5. Initialize a dataframe for the images. Include the original filename and the time in UTC, Epoch, and ISO formats.\n",
    "6. Export a CSV of the dataframe. Plot the image times and the GPX elevations by time to check that they match.\n",
    "7. Rename the photos using the survey number, the flight and camera ID, the time in ISO format, and the original filename.\n",
    "8. Geotag the photos from the GPX file using the Geosync tool in ExifTool.\n",
    "9. Update the EXIF tags to standard values.\n",
    "\n",
    "## Requirements\n",
    "Python 3 with modules (in addition to defaults):\n",
    "\n",
    "- lxml\n",
    "- PIL, which includes ExifTool by Phil Harvey\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- ipyleaflet\n",
    "\n",
    "These are satisfied by using the `IOOS3` environment in Anaconda.\n",
    "\n",
    "### To use ipyleaflet\n",
    "\n",
    "```\n",
    "conda install -c conda-forge ipyleaflet\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "pip install ipyleaflet\n",
    "jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "```\n",
    "\n",
    "\n",
    "## Inputs/outputs\n",
    "\n",
    "Variables:\n",
    "\n",
    "- homedir: working directory that contains image folder and tlog folder (with gpx file) and where outputs will be saved.\n",
    "- flight: flight ID that matches the image folder name and the gpx file, usually in format fX\n",
    "- logfile: gpx file path\n",
    "- imagefolder: image folder path\n",
    "\n",
    "Output products:\n",
    "\n",
    "- CSV of pertinent telemetry data converted from GPX\n",
    "- PNG of flight path created from GPX\n",
    "- new folder of images with standardized filenames and image headers populated with contextual information\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and define the namespace for the GPX schema\n",
    "\n",
    "If you get an error here, you will have to add packages to your Python distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string, copy, sys, subprocess\n",
    "import shutil\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lxml import etree\n",
    "from PIL import Image, ExifTags\n",
    "import ipyleaflet as ipyl\n",
    "\n",
    "# set pandas output to limit to N records\n",
    "pd.set_option('max_rows', 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set local filepaths:\n",
    "homedir = r'/Users/esturdivant/Desktop/photos_test/ricoh' # '/Data/2018_PlumIsland/2018_015_FA_PlumIs_Feb/test_script/ricoh'\n",
    "logfile = r'/Users/esturdivant/Desktop/photos_test/ricoh/f1.gpx'\n",
    "imagefolder = r'/Users/esturdivant/Desktop/photos_test/ricoh/f1'\n",
    "\n",
    "# Mission info - would be nice for logfile and image folder names to correspond to naming convention, as below\n",
    "fan = '2018-015-FA' # input('Field activity number (e.g. \"2017-010-FA\"): ')\n",
    "flight_id = 'f06' \n",
    "cam_id = 'r01' \n",
    "\n",
    "# Automated file/folder names\n",
    "navcsvoutfile = os.path.splitext(logfile)[0]+'_gpx.csv'\n",
    "imgoutdir = imagefolder+'_new'\n",
    "\n",
    "# WHSC EXIF population\n",
    "credit = \"U.S. Geological Survey\"\n",
    "comment = \"\"\"Low-altitude aerial photograph of Plum Island, MA from \n",
    "survey {0} (https://cmgds.marine.usgs.gov/fan_info.php?fa={0}).\"\"\".format(fan)\n",
    "keywords = \"Plum Island, Massachusetts, {}, UAS, nadir, USGS\".format(fan)\n",
    "artist = \"WHCMSC AIM Group\"\n",
    "contact = \"WHSC_data_contact@usgs.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ALTERNATIVE: prompt for user input\n",
    "\n",
    "# homedir = input(\"Which directory contains your raw images and telemetry data (e.g. {})? \".format(homedir))\n",
    "# flightdirname = input(\"Which flight? Must match folder name in tlogs folder (e.g. f6). \")\n",
    "# logfile = os.path.join(homedir,'tlogs', flightdirname+'.gpx')\n",
    "# imagefolder = os.path.join(homedir,'images', flightdirname)\n",
    "# fan = input('Field activity number (e.g. \"2017-010-FA\"): ')\n",
    "# flight_id = input('Flight number (e.g. \"f04\"): ') \n",
    "# cam_id = input('Camera code (e.g. \"r01\"): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the user input data looks right before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Input nav file: {}\\nOutput nav file: {}\\nWorking JPEG dir: {}\\nProcessed JPEG dir: {}\"\"\".format(\n",
    "    logfile, navcsvoutfile, imagefolder, imgoutdir))\n",
    "input_check = \"FA = {}    flight = {}    sensor = {}\".format(fan, flight_id, cam_id)\n",
    "print (\"input data: \"+ input_check)\n",
    "\n",
    "while True:\n",
    "   answer = input('Does the input data above look right?:')\n",
    "   if answer.lower().startswith(\"y\"):\n",
    "        break\n",
    "   elif answer.lower().startswith(\"n\"):\n",
    "      print(\"ok, try to re-run the script and enter the correct FA, flight and sensor\")\n",
    "      sys.exit()\n",
    "\n",
    "if not os.path.isfile(logfile):\n",
    "    print(\"We don't see the specified file (logfile variable): {}\".format(logfile))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Great!! Looks like the logfile is present as well. Carry on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse GPX file and extract components into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_tag_to_pdseries(tree, namespace, tag):\n",
    "    elist = tree.xpath('./def:trk//def:trkpt//def:'+tag, namespaces=namespace)\n",
    "    ser = pd.Series([e.text for e in elist], name=tag)\n",
    "    return(ser)\n",
    "\n",
    "# Parse GPX\n",
    "tree = etree.parse(logfile)\n",
    "\n",
    "# Extract latitude and longitude to initialize GPX dataframe\n",
    "namespace = {'def': 'http://www.topografix.com/GPX/1/1'}\n",
    "elist = tree.xpath('./def:trk//def:trkpt',namespaces=namespace)\n",
    "gpxdf = pd.DataFrame([e.values() for e in elist], columns=['lat', 'lon']).apply(pd.to_numeric)\n",
    "\n",
    "# Extract each tag (including time) and add to dataframe\n",
    "taglist = ['time', 'ele', 'ele2', 'course', 'roll', 'pitch', 'mode']\n",
    "for tag in taglist:\n",
    "    gpxdf = gpxdf.join(pd.to_numeric(gpx_tag_to_pdseries(tree, namespace, tag), errors='ignore'))\n",
    "\n",
    "# Check number of records and number of unique times \n",
    "print (\"Number of records in GPX file: \", len(gpxdf.index))\n",
    "print (\"Number of unique time stamps in GPX file: {}\\n\".format(len(gpxdf.time.unique())))\n",
    "\n",
    "gpxdf.describe()\n",
    "gpxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add datetime field to gpxdf dataframe\n",
    "\n",
    "Convert the time field to: \n",
    "\n",
    "- datetime_utc: datetime in UTC\n",
    "- epoch_utc: Unix epoch time, which counts seconds from January 1, 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in 'time' field to datetime UTC and convert datetime UTC to Epoch UTC\n",
    "tfmt_gpx = '%Y-%m-%dT%H:%M:%S' #e.g. 2017-05-04T14:14:12-04:00\n",
    "gpxdf['datetime_utc'] = pd.to_datetime(gpxdf['time'], format = tfmt_gpx)\n",
    "gpxdf['epoch_utc'] = gpxdf['datetime_utc'].astype(np.int64) // 10**9\n",
    "\n",
    "## this applies the local time zone offset to create a UTC epochtime value\n",
    "## March 2018 - commented out the tzoffset part for Plum Island survey - collected in UTC\n",
    "# gpxdf['epoch_utc'] = gpxdf['epoch_utc'].astype(str).astype(int) \n",
    "\n",
    "gpxdf_uniquetimes = gpxdf.drop_duplicates(subset='time')\n",
    "print(\"Number of records in unique times GPX file: \", len(gpxdf_uniquetimes.index))\n",
    "\n",
    "gpxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export (csv) and plot (png) the GPX data\n",
    "\n",
    "We're not sure how the interpolation works. Does simply '-' tell it to plot as a line, which includes interpolation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV\n",
    "gpxdf.to_csv(navcsvoutfile, index=False)\n",
    "print (\"Exported output CSV file to:\", navcsvoutfile,\"\\n\")\n",
    "\n",
    "# Plot the flight path\n",
    "fig = plt.figure()\n",
    "plt.plot(gpxdf.lon,gpxdf.lat,'.', c='green', label=\"GPX points\")\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(gpxdf.lon,gpxdf.lat,'-', c='yellow', label=\"GPX line interp\")\n",
    "ax.legend()\n",
    "fig.suptitle('GPX track for flight {}'.format(flight_id), fontsize=16)\n",
    "fig.savefig(os.path.join(homedir, \"{}_gpxtrack.png\".format(os.path.splitext(logfile)[0])))\n",
    "#fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot GPX on basemap – uses ipyleaflet and opens inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_to_linestring(df, lat='lat', lon='lon', z='ele'):\n",
    "    \"\"\"\n",
    "    Turn a dataframe containing point data into a linestring in geojson format\n",
    "    modified from: https://github.com/gboeing/urban-data-science/blob/3faf7e028d48cb03ddb999c5a910213c5384e7dc/17-Leaflet-Web-Mapping/leaflet-simple-demo/pandas-to-geojson.ipynb\n",
    "    \n",
    "    df : the dataframe to convert to geojson\n",
    "    lat : the name of the column in the dataframe that contains latitude data\n",
    "    lon : the name of the column in the dataframe that contains longitude data\n",
    "    \"\"\"\n",
    "    # create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    \n",
    "    # create a feature template to fill in\n",
    "    feature = {'type':'Feature',\n",
    "               'properties':{},\n",
    "               'geometry':{'type':'LineString',\n",
    "                           'coordinates':[]}}\n",
    "    \n",
    "    # loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        # fill in the coordinates\n",
    "        feature['geometry']['coordinates'].append([row[lon],row[lat],row[z]])\n",
    "\n",
    "    # add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "    geojson['features'].append(feature)\n",
    "    \n",
    "    return(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: figure out a way to cache the map layer or load a geotiff so we can do this offline\n",
    "m = ipyl.Map(\n",
    "    center=[np.mean([max(gpxdf.lat), min(gpxdf.lat)]), np.mean([max(gpxdf.lon), min(gpxdf.lon)])], \n",
    "    zoom=16, \n",
    "    layout=dict(width='600px', height='400px'), \n",
    "    basemap=ipyl.basemaps.Esri.WorldImagery)\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    print(action)\n",
    "    print(geo_json)\n",
    "    \n",
    "dc = ipyl.DrawControl()\n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "\n",
    "# Plotting the points (even only the unique times) is unwieldy. Plotting all points crashed my kernel. Plotting the unique ones worked, but there's  no apparent way to customize the point display. \n",
    "flight_path = df_to_linestring(gpxdf)\n",
    "m.add_layer(ipyl.GeoJSON(data=flight_path))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the photos\n",
    "\n",
    "Quirks from ExifTool that required work-arounds: \n",
    "\n",
    "- ExifTool assumes that both the GPS and the image times are local unless another timezone is specified (unless taken from GPSTimeStamp which is UTC).\n",
    "\n",
    "We normally set our camera to UTC and save the GPX files in UTC (by setting the computer time to UTC before running the Mission Planner conversion). Thus, running -geotag on a computer in local time without the '-geotime<${{DateTimeOriginal}}+00:00' part causes the camera times to be incorreclty adjusted to UTC. Our work-around uses the command to geotag images for which the camera clock was set to UTC (+00:00), using the time from DateTimeOriginal. It would also work to change the geosync value to account for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ExifTool command to geotag images with a GPX file\n",
    "geosync = '-0:0:0'\n",
    "# Geotag images for which the camera clock was set to UTC (+00:00), using the time from DateTimeOriginal: (from ExifTool docs)\n",
    "cmd = \"\"\"exiftool -v2 -geotag {} -geosync={} '-geotime<${{DateTimeOriginal}}+00:00' {}\"\"\".format(logfile, \n",
    "                                                                                                 geosync, imagefolder) \n",
    "subprocess.check_call(cmd, shell=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just moved the above cell up there and haven't tested the code in this order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all JPEGS in imagefolder\n",
    "flist=[os.path.join(imagefolder,f) for f in os.listdir(imagefolder) if f.lower().endswith('.jpg')]\n",
    "print(\"Found {} images in {}.\".format(len(flist),imagefolder))\n",
    "\n",
    "# Set datetime formats\n",
    "iso_fmt=\"%Y%m%dT%H%M%SZ\"\n",
    "tfmt_exif = '%Y:%m:%d %H:%M:%S' #e.g. 2017:05:04 14:14:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make dataframe of photos – get filename and DateTimeOriginal of each photo\n",
    "dt = [datetime.datetime.strptime(Image.open(f)._getexif()[36867], tfmt_exif) for f in flist]\n",
    "imgdf = pd.DataFrame({'orig_name': [os.path.basename(f) for f in flist],\n",
    "                      'time_utc': dt,\n",
    "                      'time_epoch': pd.to_datetime(dt, format = tfmt_exif).astype(np.int64) // 10**9, \n",
    "                      'time_iso': [t.strftime(iso_fmt) for t in dt],\n",
    "                      'new_name': np.nan,\n",
    "                      'lon': np.nan,\n",
    "                      'lat': np.nan,\n",
    "                      'ele': np.nan,\n",
    "                      'interpolated': 0},\n",
    "                        columns=['new_name', 'lat', 'lon', 'ele', 'time_utc', 'orig_name', \n",
    "                                 'time_epoch', 'time_iso', 'interpolated'])\n",
    "\n",
    "imgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV for original photo EXIF times\n",
    "imgcsvoutfile = imagefolder+'_imgtmp.csv'\n",
    "imgdf.to_csv(imgcsvoutfile, index=False)\n",
    "print (\"Exported photo CSV file as:\", imgcsvoutfile,\"\\n\")\n",
    "            \n",
    "# print first and last image name and times\n",
    "print(\"First file: {}, time: {}\".format(imgdf.orig_name.iloc[0],imgdf.time_utc.iloc[0]))\n",
    "print(\"Last file: {}, time: {}\".format(imgdf.orig_name.iloc[-1],imgdf.time_utc.iloc[-1]),\"\\n\")\n",
    "# print first and last times in .gpx file\n",
    "print(\"GPX data: {} from {} to {}\".format(logfile, gpxdf.datetime_utc.iloc[0],gpxdf.datetime_utc.iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot times of image vs GPX data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(gpxdf.datetime_utc, gpxdf.ele,'.c', label='GPX')\n",
    "ax.plot(imgdf.time_utc, np.tile(gpxdf.ele.max(), imgdf.shape[0]),'.r', label='photo')\n",
    "ax.legend()\n",
    "#fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: don't run if the names have already been changed...\n",
    "rename_photos = True\n",
    "\n",
    "surveyid = fan.replace(\"-\",\"\")\n",
    "if not os.path.exists(imgoutdir):\n",
    "    shutil.copytree(imagefolder, imgoutdir)\n",
    "for idx, row in imgdf.iterrows():\n",
    "    img = row.orig_name\n",
    "    namestr = \"{}_{}{}_{}_{}\".format(surveyid, flight_id, cam_id, row.time_iso, img)\n",
    "    if rename_photos:\n",
    "        os.rename(os.path.join(imagefolder, img), os.path.join(imgoutdir, namestr))\n",
    "    imgdf.loc[idx, 'new_name'] = namestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotag photos & add standard USGS metadata to EXIF headers\n",
    "I needed to hard code the location of exiftools - this might be different depending on ExifTools install. If needed, you can always run it at the command line flight-by-flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the ExifTool command to geotag images with a GPX file\n",
    "# cmd = \"\"\"exiftool -geosync=-0:0:0 -geotag {} {}\"\"\".format(logfile, imgoutdir)\n",
    "# subprocess.check_call(cmd, shell=True)\n",
    "# # Alternative?: subprocess.check_call(\"/usr/local/bin/exiftool -geosync=-0:0:0 -geotag {} {}\"\"\".format(logfile, imgoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_WHSC_exiftags(imgdir, credit, comment, keywords, artist, contact):\n",
    "    # Tags that will be identical for all images in the folder\n",
    "    tagvalues = {}\n",
    "    tagvalues['imgdir'] = imgdir\n",
    "    tagvalues['credit'] = credit\n",
    "    tagvalues['artist'] = artist\n",
    "    tagvalues['contact'] = contact\n",
    "    tagvalues['comment'] = comment\n",
    "    tagvalues['keywords'] = keywords\n",
    "    tagvalues['copyright'] = \"Public Domain. Please credit {credit}\".format(**tagvalues)\n",
    "    # Write to EXIF\n",
    "    cmd = \"\"\"exiftool -Artist=\"{artist} \" -Credit=\"{credit} \" -Contact=\"{contact} \" -comment=\"{comment} \" -sep \", \" -keywords=\"{keywords} \" -Caption=\"{comment} \" -Copyright=\"{copyright} \" -CopyrightNotice=\"{copyright} \" -Caption-Abstract=\"{comment} \" -ImageDescription=\"{comment} \" {imgdir}\"\"\".format(**tagvalues)\n",
    "    subprocess.check_call(cmd, shell=True)\n",
    "    print(\"Updated Exif headers in directory: {}\".format(imgdir))\n",
    "    return(True)\n",
    "\n",
    "# Run ExifTool again to update other USGS specific meta tags\n",
    "write_WHSC_exiftags(imgoutdir, credit, comment, keywords, artist, contact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IOOS3]",
   "language": "python",
   "name": "conda-env-IOOS3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
